---
description: 
globs: 
alwaysApply: false
---
We're building Jaib - a lightweight web application and chrome extension for reading and saving articles, similar to Pocket.

---

Technology Stack:
- Frontend: React (JSX), Vite
- Styling: Tailwind CSS (v4.1.7). 4.1.7 is different than the previous versions, in that it doesn't use tailwind.config.js. We've gone ahead and added tailwind.config.js and the typography plugin in index.css to mimic older versions so that you don't hallucinate incorrect information.
- UI Components: ShadCN UI (latest version, components located in app/components/ui/). When adding new shadcn components, please inform me first so I can install them via npm; components must always be imported from app/components/ui/.
- Icons: Lucide React
- Backend/Database: Supabase (for authentication, edge functions and data storage)

Rules of Engagement:
1. I will propose terminal commands for you to review and run; you will not execute them directly. I will pause for your confirmation after proposing a command.
2. All ShadCN UI components are located in and must be referenced from the app/components/ui/ directory.
3. We are working primarily within the  directory, located inside the main jaib/ project directory (which also contains an /extension directory for later work).
4. I have an edge function in supabase to fetch article data, called fetch-article-data. It's built using the supabase dashboard, and is not visible in local. For all supabase information, refer to app\supabase_readme.md
5. When I ask you for git commit messages, be short and to the point.

---


Our supabase schemas are located here: app\supabase_readme.md

\ is our main project directory.

\app  is our vite react JSX app

\extension  is our lightweight google chrome extension.

---

Our .env.local file is stored under \app and has the below variables:

   VITE_SUPABASE_URL
   VITE_SUPABASE_ANON_KEY
   HUGGING_FACE_API_TOKEN
   ELEVEN_LABS_API_TOKEN
   SUPABASE_SERVICE_KEY

---

## Text-to-Speech (TTS) Architecture

We use a self-hosted Kokoro TTS model (https://github.com/remsky/Kokoro-FastAPI/blob/master/README.md) running on RunPod for text-to-speech functionality. The architecture is as follows:

### Components:
1. **Frontend (ArticleView.jsx)**:
   - Uses DOM traversal to extract article text exactly as rendered
   - Splits text into manageable chunks using sentence boundaries
   - Manages audio playback state and UI
   - Located in: `app/src/components/views/ArticleView.jsx`

2. **API Layer (text-to-speech.js)**:
   - Serverless function that acts as a proxy to RunPod
   - Handles text chunks and returns audio data
   - Located in: `app/api/text-to-speech.js`

3. **TTS Engine**:
   - Kokoro TTS model running on RunPod
   - Endpoint: Custom RunPod instance URL
   - Model: `kokoro` with voice `af_bella`
   - Format: MP3 audio output

### Flow:
1. User clicks headphones icon in article view
2. Frontend extracts text from DOM using TreeWalker
3. Text is split into chunks at natural sentence boundaries
4. Each chunk is sent to `/api/text-to-speech`
5. API forwards request to RunPod instance
6. RunPod generates audio and returns MP3
7. Audio is played in sequence through HTML5 Audio element

### Key Files:
- `app/src/components/views/ArticleView.jsx`: Frontend logic and audio player
- `app/api/text-to-speech.js`: API proxy to RunPod
- `app/src/components/views/AudioPlayerCard.jsx`: Audio player UI component

### Environment Variables:
- RunPod endpoint URL is currently hardcoded in `text-to-speech.js`
- Future improvement: Move to environment variable

### Notes:
- Text extraction happens from rendered DOM, not database content
- This ensures TTS matches exactly what the user sees
- Chunks are processed sequentially to handle long articles
- Audio player supports pause/resume and maintains chunk sequence



